"""
TechLogistics S.A. - Sistema de Soporte a la Decisi√≥n (DSS)
Dashboard Principal

Autor: Consultor Data Scientist Senior
Fecha: 2026
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
import os
import io

# Importar m√≥dulos propios
from data_cleaning import (
    calculate_health_score,
    clean_inventario,
    clean_transacciones,
    clean_feedback,
    merge_datasets,
    create_derived_features,
    generate_cleaning_report,
    generate_outlier_report
)
from utils import (
    calculate_kpis,
    format_currency,
    format_percentage,
    create_health_comparison_chart,
    create_nullity_heatmap,
    create_margin_analysis_charts,
    create_logistics_charts,
    create_customer_charts,
    create_ghost_sku_charts,
    create_stock_revision_charts,
    create_fidelity_paradox_charts,
    generate_ai_insights,
    export_cleaning_report_to_csv
)

# =============================================================================
# CONFIGURACI√ìN DE P√ÅGINA
# =============================================================================
st.set_page_config(
    page_title="TechLogistics DSS",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A5F;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        border-radius: 10px;
        padding: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .kpi-value {
        font-size: 2rem;
        font-weight: 700;
        color: #1E3A5F;
    }
    .kpi-label {
        font-size: 0.9rem;
        color: #666;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #f0f2f6;
        border-radius: 4px;
        padding: 10px 20px;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffc107;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #28a745;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .danger-box {
        background-color: #f8d7da;
        border: 1px solid #dc3545;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


# =============================================================================
# FUNCIONES DE CARGA Y PROCESAMIENTO
# =============================================================================

@st.cache_data
def load_and_process_data(inv_path, trans_path, feed_path):
    """
    Carga y procesa todos los datasets.
    Usa cache para evitar reprocesamiento.
    """
    # Cargar datos crudos
    df_inventario_raw = pd.read_csv(inv_path)
    df_transacciones_raw = pd.read_csv(trans_path)
    df_feedback_raw = pd.read_csv(feed_path)
    
    # Calcular Health Score ANTES de limpieza
    health_inv_before = calculate_health_score(df_inventario_raw, "Inventario")
    health_trans_before = calculate_health_score(df_transacciones_raw, "Transacciones")
    health_feed_before = calculate_health_score(df_feedback_raw, "Feedback")
    
    # Limpiar datos
    df_inventario, log_inv = clean_inventario(df_inventario_raw)
    df_transacciones, log_trans = clean_transacciones(df_transacciones_raw)
    df_feedback, log_feed = clean_feedback(df_feedback_raw)
    
    # Calcular Health Score DESPU√âS de limpieza
    health_inv_after = calculate_health_score(df_inventario, "Inventario")
    health_trans_after = calculate_health_score(df_transacciones, "Transacciones")
    health_feed_after = calculate_health_score(df_feedback, "Feedback")
    
    # Generar reportes de limpieza
    report_inv = generate_cleaning_report(health_inv_before, health_inv_after, log_inv, "Inventario")
    report_trans = generate_cleaning_report(health_trans_before, health_trans_after, log_trans, "Transacciones")
    report_feed = generate_cleaning_report(health_feed_before, health_feed_after, log_feed, "Feedback")
    
    # Integrar datasets
    df_merged, df_fantasma, merge_stats = merge_datasets(df_inventario, df_transacciones, df_feedback)
    
    # Crear features derivadas
    df_final = create_derived_features(df_merged)
    
    return {
        'df_inventario_raw': df_inventario_raw,
        'df_transacciones_raw': df_transacciones_raw,
        'df_feedback_raw': df_feedback_raw,
        'df_inventario': df_inventario,
        'df_transacciones': df_transacciones,
        'df_feedback': df_feedback,
        'df_merged': df_final,
        'df_fantasma': df_fantasma,
        'merge_stats': merge_stats,
        'reports': [report_inv, report_trans, report_feed],
        'cleaning_logs': {
            'inventario': log_inv,
            'transacciones': log_trans,
            'feedback': log_feed
        },
        'health_before': {
            'Inventario': health_inv_before,
            'Transacciones': health_trans_before,
            'Feedback': health_feed_before
        },
        'health_after': {
            'Inventario': health_inv_after,
            'Transacciones': health_trans_after,
            'Feedback': health_feed_after
        }
    }


def apply_filters(df, filters):
    """
    Aplica los filtros seleccionados al DataFrame.
    """
    df_filtered = df.copy()
    
    # Filtro de fechas
    if filters.get('fecha_inicio') and filters.get('fecha_fin'):
        df_filtered = df_filtered[
            (df_filtered['Fecha_Venta'] >= pd.Timestamp(filters['fecha_inicio'])) &
            (df_filtered['Fecha_Venta'] <= pd.Timestamp(filters['fecha_fin']))
        ]
    
    # Filtro de categor√≠a
    if filters.get('categorias') and len(filters['categorias']) > 0:
        df_filtered = df_filtered[df_filtered['Categoria'].isin(filters['categorias'])]
    
    # Filtro de bodega
    if filters.get('bodegas') and len(filters['bodegas']) > 0:
        df_filtered = df_filtered[df_filtered['Bodega_Origen'].isin(filters['bodegas'])]
    
    # Filtro de ciudad
    if filters.get('ciudades') and len(filters['ciudades']) > 0:
        df_filtered = df_filtered[df_filtered['Ciudad_Destino'].isin(filters['ciudades'])]
    
    # Filtro de canal
    if filters.get('canales') and len(filters['canales']) > 0:
        df_filtered = df_filtered[df_filtered['Canal_Venta'].isin(filters['canales'])]
    
    # Filtro de incluir SKUs fantasma
    if not filters.get('incluir_fantasma', True):
        df_filtered = df_filtered[df_filtered['SKU_Fantasma'] == False]
    
    # Filtro de excluir outliers de costo
    if filters.get('excluir_outliers', False):
        df_filtered = df_filtered[df_filtered['Costo_Outlier_Flag'] == False]
    
    return df_filtered


# =============================================================================
# BARRA LATERAL
# =============================================================================

def render_sidebar(data):
    """
    Renderiza la barra lateral con filtros y controles.
    """
    st.sidebar.markdown("## üéõÔ∏è Panel de Control")
    st.sidebar.markdown("---")
    
    df = data['df_merged']
    
    # Informaci√≥n general
    st.sidebar.markdown("### üìä Resumen de Datos")
    st.sidebar.info(f"""
    **Transacciones:** {len(df):,}
    **SKUs √önicos:** {df['SKU_ID'].nunique():,}
    **Periodo:** {df['Fecha_Venta'].min().strftime('%Y-%m-%d')} a {df['Fecha_Venta'].max().strftime('%Y-%m-%d')}
    """)
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ‚öôÔ∏è Opciones de An√°lisis")
    
    filters = {}
    
    filters['incluir_fantasma'] = st.sidebar.checkbox(
        "Incluir SKUs Fantasma",
        value=True,
        help="Incluir ventas de productos no catalogados en inventario"
    )
    
    filters['excluir_outliers'] = st.sidebar.checkbox(
        "Excluir Outliers de Costo",
        value=False,
        help="Excluir productos con costos an√≥malos detectados por IQR"
    )
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üîç Filtros")
    
    # Filtro de fechas
    col1, col2 = st.sidebar.columns(2)
    with col1:
        filters['fecha_inicio'] = st.date_input(
            "Desde",
            value=df['Fecha_Venta'].min().date(),
            min_value=df['Fecha_Venta'].min().date(),
            max_value=df['Fecha_Venta'].max().date()
        )
    with col2:
        filters['fecha_fin'] = st.date_input(
            "Hasta",
            value=df['Fecha_Venta'].max().date(),
            min_value=df['Fecha_Venta'].min().date(),
            max_value=df['Fecha_Venta'].max().date()
        )
    
    # Filtro de categor√≠a
    categorias_disponibles = sorted(df['Categoria'].dropna().unique().tolist())
    filters['categorias'] = st.sidebar.multiselect(
        "Categor√≠as",
        options=categorias_disponibles,
        default=[]
    )
    
    # Filtro de bodega
    bodegas_disponibles = sorted(df['Bodega_Origen'].dropna().unique().tolist())
    filters['bodegas'] = st.sidebar.multiselect(
        "Bodegas",
        options=bodegas_disponibles,
        default=[]
    )
    
    # Filtro de ciudad
    ciudades_disponibles = sorted(df['Ciudad_Destino'].dropna().unique().tolist())
    filters['ciudades'] = st.sidebar.multiselect(
        "Ciudades",
        options=ciudades_disponibles,
        default=[]
    )
    
    # Filtro de canal
    canales_disponibles = sorted(df['Canal_Venta'].dropna().unique().tolist())
    filters['canales'] = st.sidebar.multiselect(
        "Canales de Venta",
        options=canales_disponibles,
        default=[]
    )
    
    st.sidebar.markdown("---")
    
    # Bot√≥n de refrescar
    if st.sidebar.button("üîÑ Refrescar An√°lisis", use_container_width=True):
        st.cache_data.clear()
        st.rerun()
    
    return filters


# =============================================================================
# TABS DE CONTENIDO
# =============================================================================

def render_auditoria_tab(data):
    """
    Renderiza la pesta√±a de Auditor√≠a de Calidad.
    """
    st.markdown("## üî¨ Auditor√≠a de Calidad de Datos")
    st.markdown("""
    Esta secci√≥n presenta el an√°lisis de calidad de los datos **antes y despu√©s** del proceso de limpieza,
    incluyendo m√©tricas de completitud, unicidad y validez.
    """)
    
    reports = data['reports']
    
    # Health Scores comparativos
    st.markdown("### üìà Health Score por Dataset")
    
    cols = st.columns(3)
    for i, report in enumerate(reports):
        with cols[i]:
            delta = report['mejora_health_score']
            st.metric(
                label=f"**{report['dataset']}**",
                value=f"{report['metricas_despues']['health_score']:.1f}%",
                delta=f"+{delta:.1f}%" if delta >= 0 else f"{delta:.1f}%"
            )
    
    st.markdown("---")
    
    # Gr√°ficos de comparaci√≥n
    st.markdown("### üìä Comparaci√≥n Antes vs Despu√©s")
    
    for report in reports:
        with st.expander(f"üìÅ {report['dataset']}", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                # Gr√°fico de health score
                fig_health = create_health_comparison_chart(report)
                st.plotly_chart(fig_health, use_container_width=True)
            
            with col2:
                # Gr√°fico de nulidad
                fig_null = create_nullity_heatmap(
                    report['nulidad_por_columna_despues'],
                    report['dataset']
                )
                st.plotly_chart(fig_null, use_container_width=True)
            
            # Detalles de limpieza
            st.markdown("#### üìã Acciones de Limpieza Realizadas")
            for accion in report['acciones_realizadas']:
                st.markdown(f"- {accion}")
            
            # Imputaciones
            if report.get('imputaciones'):
                st.markdown("#### üîß Decisiones de Imputaci√≥n")
                for col, info in report['imputaciones'].items():
                    st.markdown(f"""
                    **{col}:**
                    - M√©todo: {info['metodo']}
                    - Justificaci√≥n: {info['justificacion']}
                    - Valores imputados: {info['valores_imputados']}
                    """)
            
            # Outliers
            if report.get('outliers_detectados'):
                st.markdown("#### ‚ö†Ô∏è Outliers Detectados")
                for col, info in report['outliers_detectados'].items():
                    st.warning(f"**{col}:** {info.get('cantidad', 'N/A')} outliers detectados")
    
    # ==========================================================================
    # SECCI√ìN DE VISUALIZACI√ìN DE OUTLIERS (VALORES ORIGINALES)
    # ==========================================================================
    st.markdown("---")
    st.markdown("### üîç Registros Outliers Detectados (Valores Originales)")
    st.markdown("""
    A continuaci√≥n puede explorar los registros espec√≠ficos que fueron identificados como outliers 
    o valores an√≥malos en cada dataset. **Se muestran los valores ORIGINALES antes de cualquier correcci√≥n o imputaci√≥n.**
    """)
    
    # Obtener los logs de limpieza con los DataFrames originales
    cleaning_logs = data.get('cleaning_logs', {})
    
    # --- OUTLIERS DE INVENTARIO ---
    st.markdown("#### üì¶ Dataset: Inventario")
    log_inv = cleaning_logs.get('inventario', {})
    outliers_inv = log_inv.get('outliers_dataframes', {})
    
    # Outliers de costo (valores originales)
    df_costo_outliers = outliers_inv.get('costo_outliers')
    if df_costo_outliers is not None and len(df_costo_outliers) > 0:
        with st.expander(f"üí∞ Outliers de Costo Unitario ({len(df_costo_outliers)} registros)", expanded=False):
            st.markdown("""
            **Criterio de detecci√≥n:** M√©todo IQR (Rango Intercuart√≠lico) con multiplicador 3.
            Estos productos tienen costos unitarios significativamente fuera del rango normal.
            **Nota:** Se muestran los valores ORIGINALES sin modificar.
            """)
            st.dataframe(
                df_costo_outliers.sort_values('Costo_Unitario_USD', ascending=False),
                use_container_width=True,
                height=300
            )
            # Estad√≠sticas
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Costo M√≠nimo", f"${df_costo_outliers['Costo_Unitario_USD'].min():,.2f}")
            with col2:
                st.metric("Costo M√°ximo", f"${df_costo_outliers['Costo_Unitario_USD'].max():,.2f}")
            with col3:
                st.metric("Costo Promedio", f"${df_costo_outliers['Costo_Unitario_USD'].mean():,.2f}")
    else:
        with st.expander("üí∞ Outliers de Costo Unitario (0 registros)", expanded=False):
            st.success("No se detectaron outliers de costo.")
    
    # Stock negativo (valores originales)
    df_stock_negativo = outliers_inv.get('stock_negativo')
    if df_stock_negativo is not None and len(df_stock_negativo) > 0:
        with st.expander(f"üìâ Registros con Stock Negativo Original ({len(df_stock_negativo)} registros)", expanded=False):
            st.markdown("""
            **Anomal√≠a:** Estos productos ten√≠an stock negativo en el sistema original, 
            lo cual es contablemente imposible. Fueron corregidos a 0 durante la limpieza.
            **Nota:** Se muestran los valores ORIGINALES (negativos) antes de la correcci√≥n.
            """)
            st.dataframe(
                df_stock_negativo.sort_values('Stock_Original'),
                use_container_width=True,
                height=300
            )
            # Estad√≠sticas
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Stock M√°s Negativo", f"{df_stock_negativo['Stock_Original'].min():,.0f} unidades")
            with col2:
                st.metric("Promedio Stock Negativo", f"{df_stock_negativo['Stock_Original'].mean():,.1f} unidades")
    else:
        with st.expander("üìâ Registros con Stock Negativo Original (0 registros)", expanded=False):
            st.success("No se detectaron registros con stock negativo.")
    
    # --- OUTLIERS DE TRANSACCIONES ---
    st.markdown("#### üöö Dataset: Transacciones")
    log_trans = cleaning_logs.get('transacciones', {})
    outliers_trans = log_trans.get('outliers_dataframes', {})
    
    # Outliers de tiempo de entrega (valores originales)
    df_tiempo_outliers = outliers_trans.get('tiempo_entrega_outliers')
    if df_tiempo_outliers is not None and len(df_tiempo_outliers) > 0:
        with st.expander(f"‚è±Ô∏è Outliers de Tiempo de Entrega ({len(df_tiempo_outliers)} registros)", expanded=False):
            st.markdown("""
            **Criterio de detecci√≥n:** M√©todo IQR con multiplicador 3.
            Estos pedidos tienen tiempos de entrega extremadamente altos o inusuales.
            Valores mayores a 90 d√≠as fueron capeados durante la limpieza.
            **Nota:** Se muestran los valores ORIGINALES antes del capeo.
            """)
            st.dataframe(
                df_tiempo_outliers.sort_values('Tiempo_Entrega_Original', ascending=False),
                use_container_width=True,
                height=300
            )
            # Estad√≠sticas
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Tiempo M√≠nimo", f"{df_tiempo_outliers['Tiempo_Entrega_Original'].min():.0f} d√≠as")
            with col2:
                st.metric("Tiempo M√°ximo", f"{df_tiempo_outliers['Tiempo_Entrega_Original'].max():.0f} d√≠as")
            with col3:
                st.metric("Tiempo Promedio", f"{df_tiempo_outliers['Tiempo_Entrega_Original'].mean():.1f} d√≠as")
    else:
        with st.expander("‚è±Ô∏è Outliers de Tiempo de Entrega (0 registros)", expanded=False):
            st.success("No se detectaron outliers de tiempo de entrega.")
    
    # Cantidades negativas (valores originales)
    df_cant_negativas = outliers_trans.get('cantidades_negativas')
    if df_cant_negativas is not None and len(df_cant_negativas) > 0:
        with st.expander(f"üî¢ Transacciones con Cantidad Negativa Original ({len(df_cant_negativas)} registros)", expanded=False):
            st.markdown("""
            **Anomal√≠a:** Estas transacciones ten√≠an cantidades negativas, lo cual podr√≠a indicar 
            devoluciones mal registradas o errores de digitaci√≥n. Fueron convertidas a valor absoluto.
            **Nota:** Se muestran los valores ORIGINALES (negativos) antes de la correcci√≥n.
            """)
            st.dataframe(
                df_cant_negativas.sort_values('Cantidad_Original'),
                use_container_width=True,
                height=300
            )
            # Estad√≠sticas
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Cantidad M√°s Negativa", f"{df_cant_negativas['Cantidad_Original'].min():,.0f}")
            with col2:
                st.metric("Promedio", f"{df_cant_negativas['Cantidad_Original'].mean():,.1f}")
    else:
        with st.expander("üî¢ Transacciones con Cantidad Negativa Original (0 registros)", expanded=False):
            st.success("No se detectaron transacciones con cantidad negativa.")
    
    # Fechas futuras (valores originales)
    df_fechas_futuras = outliers_trans.get('fechas_futuras')
    if df_fechas_futuras is not None and len(df_fechas_futuras) > 0:
        with st.expander(f"üìÖ Transacciones con Fecha Futura ({len(df_fechas_futuras)} registros)", expanded=False):
            st.markdown("""
            **Anomal√≠a:** Estas transacciones tienen fechas posteriores a la fecha actual,
            lo cual indica errores en la captura de datos o problemas de sincronizaci√≥n de sistemas.
            **Nota:** Se muestra tanto la fecha original como la fecha parseada.
            """)
            # Mostrar columnas relevantes
            cols_mostrar = ['Transaccion_ID', 'SKU_ID', 'Fecha_Venta_Original', 'Fecha_Venta', 'Cantidad_Vendida', 'Precio_Venta_Final', 'Canal_Venta']
            cols_disponibles = [c for c in cols_mostrar if c in df_fechas_futuras.columns]
            st.dataframe(
                df_fechas_futuras[cols_disponibles].sort_values('Fecha_Venta', ascending=False),
                use_container_width=True,
                height=300
            )
    else:
        with st.expander("üìÖ Transacciones con Fecha Futura (0 registros)", expanded=False):
            st.success("No se detectaron transacciones con fecha futura.")
    
    # --- OUTLIERS DE FEEDBACK ---
    st.markdown("#### üë• Dataset: Feedback")
    log_feed = cleaning_logs.get('feedback', {})
    outliers_feed = log_feed.get('outliers_dataframes', {})
    
    # Edades inv√°lidas (valores originales)
    df_edades_invalidas = outliers_feed.get('edades_invalidas')
    if df_edades_invalidas is not None and len(df_edades_invalidas) > 0:
        with st.expander(f"üéÇ Registros con Edad Inv√°lida Original ({len(df_edades_invalidas)} registros)", expanded=False):
            st.markdown("""
            **Criterio:** Edades fuera del rango 18-100 a√±os fueron consideradas inv√°lidas.
            Estos valores fueron imputados con la mediana de edades v√°lidas.
            **Nota:** Se muestran las edades ORIGINALES antes de la imputaci√≥n.
            """)
            st.dataframe(
                df_edades_invalidas.sort_values('Edad_Original', ascending=False),
                use_container_width=True,
                height=300
            )
            # Estad√≠sticas de edades inv√°lidas
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Edad M√≠nima", f"{df_edades_invalidas['Edad_Original'].min():.0f} a√±os")
            with col2:
                st.metric("Edad M√°xima", f"{df_edades_invalidas['Edad_Original'].max():.0f} a√±os")
            with col3:
                st.metric("Edad Promedio", f"{df_edades_invalidas['Edad_Original'].mean():.1f} a√±os")
    else:
        with st.expander("üéÇ Registros con Edad Inv√°lida Original (0 registros)", expanded=False):
            st.success("No se detectaron edades inv√°lidas.")
    
    # Ratings inv√°lidos (valores originales)
    df_ratings_invalidos = outliers_feed.get('ratings_invalidos')
    if df_ratings_invalidos is not None and len(df_ratings_invalidos) > 0:
        with st.expander(f"‚≠ê Registros con Rating Inv√°lido Original ({len(df_ratings_invalidos)} registros)", expanded=False):
            st.markdown("""
            **Criterio:** Ratings fuera del rango 1-5 fueron considerados inv√°lidos.
            Estos valores fueron capeados a los l√≠mites del rango v√°lido.
            **Nota:** Se muestran los ratings ORIGINALES antes del capeo.
            """)
            st.dataframe(
                df_ratings_invalidos.sort_values('Rating_Producto_Original', ascending=False),
                use_container_width=True,
                height=300
            )
            # Estad√≠sticas
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Rating M√≠nimo", f"{df_ratings_invalidos['Rating_Producto_Original'].min():.0f}")
            with col2:
                st.metric("Rating M√°ximo", f"{df_ratings_invalidos['Rating_Producto_Original'].max():.0f}")
    else:
        with st.expander("‚≠ê Registros con Rating Inv√°lido Original (0 registros)", expanded=False):
            st.success("No se detectaron ratings inv√°lidos.")
    
    # Estad√≠sticas de integraci√≥n
    st.markdown("---")
    st.markdown("### üîó Estad√≠sticas de Integraci√≥n")
    
    merge_stats = data['merge_stats']
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Transacciones Totales", f"{merge_stats['transacciones_totales']:,}")
    with col2:
        st.metric("SKUs en Inventario", f"{merge_stats['skus_en_inventario']:,}")
    with col3:
        st.metric("SKUs Fantasma", f"{merge_stats['skus_fantasma_unicos']:,}")
    with col4:
        st.metric("% Ventas Sin Cat√°logo", f"{merge_stats['porcentaje_ventas_fantasma']:.1f}%")
    
    # Bot√≥n de descarga del reporte
    st.markdown("---")
    st.markdown("### üì• Descargar Reporte de Limpieza")
    
    # Crear CSV del reporte
    report_buffer = io.StringIO()
    df_report = export_cleaning_report_to_csv(reports, report_buffer)
    
    # Preparar contenido para descarga
    report_content = []
    report_content.append("REPORTE DE AUDITOR√çA DE CALIDAD DE DATOS")
    report_content.append(f"Fecha de generaci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_content.append("=" * 80)
    report_content.append("")
    
    for report in reports:
        report_content.append(f"\n{'='*40}")
        report_content.append(f"DATASET: {report['dataset']}")
        report_content.append(f"{'='*40}")
        report_content.append(f"\nM√âTRICAS ANTES:")
        report_content.append(f"  - Health Score: {report['metricas_antes']['health_score']}%")
        report_content.append(f"  - Completitud: {report['metricas_antes']['completitud']}%")
        report_content.append(f"  - Unicidad: {report['metricas_antes']['unicidad']}%")
        report_content.append(f"  - Registros: {report['metricas_antes']['registros']}")
        report_content.append(f"  - Celdas Nulas: {report['metricas_antes']['celdas_nulas']}")
        report_content.append(f"  - Duplicados: {report['metricas_antes']['duplicados']}")
        
        report_content.append(f"\nM√âTRICAS DESPU√âS:")
        report_content.append(f"  - Health Score: {report['metricas_despues']['health_score']}%")
        report_content.append(f"  - Completitud: {report['metricas_despues']['completitud']}%")
        report_content.append(f"  - Unicidad: {report['metricas_despues']['unicidad']}%")
        report_content.append(f"  - Registros: {report['metricas_despues']['registros']}")
        report_content.append(f"  - Celdas Nulas: {report['metricas_despues']['celdas_nulas']}")
        report_content.append(f"  - Duplicados: {report['metricas_despues']['duplicados']}")
        
        report_content.append(f"\nMEJORA EN HEALTH SCORE: +{report['mejora_health_score']}%")
        
        report_content.append(f"\nACCIONES REALIZADAS:")
        for accion in report['acciones_realizadas']:
            report_content.append(f"  - {accion}")
        
        if report.get('imputaciones'):
            report_content.append(f"\nIMPUTACIONES:")
            for col, info in report['imputaciones'].items():
                report_content.append(f"  {col}:")
                report_content.append(f"    - M√©todo: {info['metodo']}")
                report_content.append(f"    - Justificaci√≥n: {info['justificacion']}")
                report_content.append(f"    - Valores imputados: {info['valores_imputados']}")
        
        if report.get('outliers_detectados'):
            report_content.append(f"\nOUTLIERS DETECTADOS:")
            for col, info in report['outliers_detectados'].items():
                report_content.append(f"  {col}: {info}")
        
        report_content.append(f"\nNULIDAD POR COLUMNA (DESPU√âS):")
        for col, pct in report['nulidad_por_columna_despues'].items():
            report_content.append(f"  - {col}: {pct}%")
    
    report_text = "\n".join(report_content)
    
    st.download_button(
        label="üìÑ Descargar Reporte Completo (TXT)",
        data=report_text,
        file_name=f"reporte_auditoria_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
        mime="text/plain"
    )


def render_operaciones_tab(df_filtered, data):
    """
    Renderiza la pesta√±a de Operaciones (Preguntas 1, 2, 3 de Alta Gerencia).
    """
    st.markdown("## üè≠ An√°lisis Operacional")
    
    kpis = calculate_kpis(df_filtered)
    
    # KPIs principales
    st.markdown("### üìä KPIs Operacionales")
    
    # Usar contenedores con markdown para evitar truncamiento
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        st.markdown("**Ingresos Totales**")
        st.markdown(f"### ${kpis['ingresos_totales']:,.2f}")
    with col2:
        st.markdown("**Margen Total**")
        st.markdown(f"### ${kpis['margen_total']:,.2f}")
        st.caption(f"üìà {kpis['margen_porcentaje_global']:.1f}%")
    with col3:
        st.markdown("**P√©rdidas (Margen -)**")
        st.markdown(f"### ${kpis['perdidas_margen_negativo']:,.2f}")
        st.caption(f"üîª {kpis['transacciones_margen_negativo']:,} txn")
    with col4:
        st.markdown("**Tiempo Entrega Prom.**")
        st.markdown(f"### {kpis['tiempo_entrega_promedio']:.1f} d√≠as")
    with col5:
        st.markdown("**Entregas Retrasadas**")
        st.markdown(f"### {kpis['porcentaje_entregas_retrasadas']:.1f}%")
        st.caption(f"üì¶ {kpis['entregas_retrasadas']:,} entregas")
    
    st.markdown("---")
    
    # ==========================================================================
    # PREGUNTA 1: Fuga de Capital y Rentabilidad
    # ==========================================================================
    st.markdown("### üí∞ Pregunta 1: Fuga de Capital y Rentabilidad")
    st.markdown("""
    > *¬øCu√°les SKUs se venden con margen negativo? ¬øEs p√©rdida aceptable por volumen 
    > o falla cr√≠tica de precios en el canal Online?*
    """)
    
    margin_charts = create_margin_analysis_charts(df_filtered)
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(margin_charts['distribucion_margen'], use_container_width=True)
    with col2:
        st.plotly_chart(margin_charts['margen_categoria'], use_container_width=True)
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(margin_charts['skus_perdida'], use_container_width=True)
    with col2:
        st.plotly_chart(margin_charts['margen_canal'], use_container_width=True)
    
    # An√°lisis adicional por canal
    df_valid = df_filtered[df_filtered['SKU_Fantasma'] == False]
    canal_perdidas = df_valid[df_valid['Margen_Negativo'] == True].groupby('Canal_Venta').agg({
        'Margen_Total': 'sum',
        'Transaccion_ID': 'count'
    }).reset_index()
    canal_perdidas.columns = ['Canal', 'P√©rdida Total', 'Transacciones']
    
    st.markdown("#### üìã Resumen de P√©rdidas por Canal")
    st.dataframe(
        canal_perdidas.style.format({'P√©rdida Total': '${:,.2f}'}),
        use_container_width=True
    )
    
    # Gr√°fico de p√©rdidas por canal
    fig_perdida_canal = px.bar(
        canal_perdidas,
        x='Canal',
        y='P√©rdida Total',
        color='Transacciones',
        title='P√©rdidas por Margen Negativo seg√∫n Canal de Venta',
        color_continuous_scale='Reds'
    )
    fig_perdida_canal.update_layout(template='plotly_white', height=400)
    st.plotly_chart(fig_perdida_canal, use_container_width=True)
    
    st.markdown("---")
    
    # ==========================================================================
    # PREGUNTA 2: Crisis Log√≠stica y Cuellos de Botella
    # ==========================================================================
    st.markdown("### üöö Pregunta 2: Crisis Log√≠stica y Cuellos de Botella")
    st.markdown("""
    > *¬øEn qu√© ciudades y bodegas la correlaci√≥n entre Tiempo de Entrega y NPS bajo es m√°s fuerte?
    > ¬øQu√© zona requiere cambio inmediato de operador?*
    """)
    
    logistics_charts = create_logistics_charts(df_filtered)
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(logistics_charts['tiempo_nps_ciudad'], use_container_width=True)
    with col2:
        st.plotly_chart(logistics_charts['estado_envio'], use_container_width=True)
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(logistics_charts['rendimiento_bodega'], use_container_width=True)
    with col2:
        st.plotly_chart(logistics_charts['evolucion_entrega'], use_container_width=True)
    
    # An√°lisis de correlaci√≥n ciudad-NPS
    df_logistica = df_filtered[df_filtered['Satisfaccion_NPS'].notna()].copy()
    correlacion_ciudad = df_logistica.groupby('Ciudad_Destino').agg({
        'Tiempo_Entrega_Real': 'mean',
        'Satisfaccion_NPS': 'mean',
        'Transaccion_ID': 'count'
    }).reset_index()
    correlacion_ciudad.columns = ['Ciudad', 'Tiempo Entrega', 'NPS', 'Transacciones']
    correlacion_ciudad = correlacion_ciudad[correlacion_ciudad['Transacciones'] >= 30]
    correlacion_ciudad['Riesgo'] = correlacion_ciudad['Tiempo Entrega'] / correlacion_ciudad['NPS'].abs().clip(lower=1)
    correlacion_ciudad = correlacion_ciudad.sort_values('Riesgo', ascending=False)
    
    st.markdown("#### üéØ Ciudades con Mayor Riesgo Log√≠stico")
    st.dataframe(
        correlacion_ciudad.head(10).style.format({
            'Tiempo Entrega': '{:.1f} d√≠as',
            'NPS': '{:.1f}',
            'Riesgo': '{:.2f}'
        }),
        use_container_width=True
    )
    
    # Matriz de correlaci√≥n Tiempo de Entrega vs NPS por Ciudad
    st.markdown("#### üìä Matriz de Correlaci√≥n: Tiempo de Entrega vs NPS")
    
    # Crear datos para la matriz de correlaci√≥n
    df_corr_data = df_filtered[df_filtered['Satisfaccion_NPS'].notna()].copy()
    
    # Calcular correlaci√≥n por ciudad
    ciudades_con_datos = df_corr_data.groupby('Ciudad_Destino').filter(lambda x: len(x) >= 20)['Ciudad_Destino'].unique()
    
    correlaciones_ciudad = []
    for ciudad in ciudades_con_datos:
        df_ciudad = df_corr_data[df_corr_data['Ciudad_Destino'] == ciudad]
        if len(df_ciudad) >= 20:
            corr = df_ciudad['Tiempo_Entrega_Real'].corr(df_ciudad['Satisfaccion_NPS'])
            correlaciones_ciudad.append({
                'Ciudad': ciudad,
                'Correlaci√≥n': corr,
                'N_Muestras': len(df_ciudad),
                'Tiempo_Prom': df_ciudad['Tiempo_Entrega_Real'].mean(),
                'NPS_Prom': df_ciudad['Satisfaccion_NPS'].mean()
            })
    
    if correlaciones_ciudad:
        df_correlaciones = pd.DataFrame(correlaciones_ciudad).sort_values('Correlaci√≥n')
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Gr√°fico de barras de correlaci√≥n por ciudad
            fig_corr_bars = px.bar(
                df_correlaciones,
                x='Correlaci√≥n',
                y='Ciudad',
                orientation='h',
                color='Correlaci√≥n',
                color_continuous_scale='RdYlGn_r',
                title='Correlaci√≥n Tiempo-NPS por Ciudad',
                hover_data=['N_Muestras', 'Tiempo_Prom', 'NPS_Prom']
            )
            fig_corr_bars.add_vline(x=0, line_dash="dash", line_color="gray")
            fig_corr_bars.update_layout(template='plotly_white', height=450)
            st.plotly_chart(fig_corr_bars, use_container_width=True)
        
        with col2:
            # Crear matriz de correlaci√≥n con variables num√©ricas
            variables_corr = ['Tiempo_Entrega_Real', 'Satisfaccion_NPS', 'Rating_Logistica', 'Rating_Producto']
            df_vars = df_corr_data[variables_corr].dropna()
            
            if len(df_vars) > 0:
                matriz_corr = df_vars.corr()
                
                fig_matriz = px.imshow(
                    matriz_corr,
                    text_auto='.2f',
                    color_continuous_scale='RdBu_r',
                    title='Matriz de Correlaci√≥n: Variables de Servicio',
                    aspect='auto'
                )
                fig_matriz.update_layout(template='plotly_white', height=450)
                st.plotly_chart(fig_matriz, use_container_width=True)
        
        # Estad√≠sticas de correlaci√≥n
        corr_global = df_corr_data['Tiempo_Entrega_Real'].corr(df_corr_data['Satisfaccion_NPS'])
        ciudades_corr_negativa = df_correlaciones[df_correlaciones['Correlaci√≥n'] < -0.1]
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Correlaci√≥n Global", f"{corr_global:.3f}")
        with col2:
            st.metric("Ciudades con Correlaci√≥n Negativa", f"{len(ciudades_corr_negativa)}")
        with col3:
            if len(ciudades_corr_negativa) > 0:
                peor_ciudad = ciudades_corr_negativa.iloc[0]
                st.metric("Ciudad M√°s Cr√≠tica", f"{peor_ciudad['Ciudad']}", 
                         delta=f"r = {peor_ciudad['Correlaci√≥n']:.3f}", delta_color="inverse")
        
        # Interpretaci√≥n
        if corr_global < -0.3:
            st.error(f"""
            ‚ö†Ô∏è **Alerta Cr√≠tica:** La correlaci√≥n global es **{corr_global:.3f}**, lo que indica una relaci√≥n 
            negativa moderada-fuerte entre el tiempo de entrega y la satisfacci√≥n del cliente.
            A mayor tiempo de entrega, menor NPS.
            """)
        elif corr_global < -0.1:
            st.warning(f"""
            ‚ö° **Atenci√≥n:** La correlaci√≥n global es **{corr_global:.3f}**, indicando una relaci√≥n negativa 
            leve entre tiempo de entrega y satisfacci√≥n. Se recomienda optimizar la log√≠stica.
            """)
        else:
            st.info(f"""
            ‚ÑπÔ∏è La correlaci√≥n global es **{corr_global:.3f}**. No hay una relaci√≥n lineal fuerte entre 
            tiempo de entrega y NPS a nivel global, pero pueden existir patrones por ciudad o segmento.
            """)
    
    # Mapa de calor bodega-ciudad
    heatmap_data = df_filtered.groupby(['Bodega_Origen', 'Ciudad_Destino']).agg({
        'Tiempo_Entrega_Real': 'mean'
    }).reset_index()
    heatmap_data = heatmap_data[heatmap_data['Bodega_Origen'].notna()]
    heatmap_pivot = heatmap_data.pivot(index='Bodega_Origen', columns='Ciudad_Destino', values='Tiempo_Entrega_Real')
    
    fig_heatmap = px.imshow(
        heatmap_pivot,
        color_continuous_scale='RdYlGn_r',
        title='Tiempo de Entrega: Bodega ‚Üí Ciudad (d√≠as)',
        aspect='auto'
    )
    fig_heatmap.update_layout(height=500)
    st.plotly_chart(fig_heatmap, use_container_width=True)
    
    st.markdown("---")
    
    # ==========================================================================
    # PREGUNTA 3: An√°lisis de la Venta Invisible (SKUs Fantasma)
    # ==========================================================================
    st.markdown("### üëª Pregunta 3: An√°lisis de la Venta Invisible")
    st.markdown("""
    > *¬øCu√°l es el impacto financiero de las ventas de SKUs no catalogados?
    > ¬øQu√© porcentaje del ingreso total est√° en riesgo por falta de control de inventario?*
    """)
    
    ghost_charts = create_ghost_sku_charts(df_filtered, data['df_fantasma'])
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(ghost_charts['comparativa_fantasma'], use_container_width=True)
    with col2:
        st.plotly_chart(ghost_charts['fantasma_canal'], use_container_width=True)
    
    st.plotly_chart(ghost_charts['impacto_fantasma'], use_container_width=True)
    
    # Resumen financiero de SKUs fantasma
    fantasma_stats = df_filtered[df_filtered['SKU_Fantasma'] == True].agg({
        'Ingreso_Total': ['sum', 'mean', 'count'],
        'Cantidad_Vendida': 'sum'
    })
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Ingresos en Riesgo", format_currency(kpis['ingresos_sku_fantasma']))
    with col2:
        st.metric("% del Ingreso Total", format_percentage(kpis['porcentaje_ingresos_fantasma']))
    with col3:
        st.metric("Transacciones Afectadas", f"{kpis['ventas_sku_fantasma']:,}")
    with col4:
        skus_fantasma_unicos = df_filtered[df_filtered['SKU_Fantasma'] == True]['SKU_ID'].nunique()
        st.metric("SKUs No Catalogados", f"{skus_fantasma_unicos:,}")
    
    # Lista de SKUs fantasma
    with st.expander("üìã Ver Lista Completa de SKUs Fantasma"):
        df_fantasma_detail = df_filtered[df_filtered['SKU_Fantasma'] == True].groupby('SKU_ID').agg({
            'Ingreso_Total': 'sum',
            'Cantidad_Vendida': 'sum',
            'Transaccion_ID': 'count',
            'Canal_Venta': lambda x: x.mode()[0] if len(x.mode()) > 0 else 'N/A'
        }).reset_index().sort_values('Ingreso_Total', ascending=False)
        df_fantasma_detail.columns = ['SKU_ID', 'Ingresos', 'Unidades', 'Transacciones', 'Canal Principal']
        st.dataframe(
            df_fantasma_detail.style.format({'Ingresos': '${:,.2f}'}),
            use_container_width=True
        )


def render_cliente_tab(df_filtered, data):
    """
    Renderiza la pesta√±a de Cliente (Preguntas 4 y 5 de Alta Gerencia).
    """
    st.markdown("## üë• An√°lisis de Cliente y Satisfacci√≥n")
    
    kpis = calculate_kpis(df_filtered)
    
    # KPIs de cliente
    st.markdown("### üìä KPIs de Satisfacci√≥n")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("NPS Promedio", f"{kpis['nps_promedio']:.1f}",
                 delta="Promotor" if kpis['nps_promedio'] >= 50 else ("Pasivo" if kpis['nps_promedio'] >= 0 else "Detractor"))
    with col2:
        st.metric("Rating Producto", f"{kpis['rating_producto_promedio']:.2f}/5")
    with col3:
        st.metric("Rating Log√≠stica", f"{kpis['rating_logistica_promedio']:.2f}/5")
    with col4:
        st.metric("Tasa Tickets Soporte", format_percentage(kpis['porcentaje_tickets_soporte']))
    
    st.markdown("---")
    
    # ==========================================================================
    # PREGUNTA 4: Diagn√≥stico de Fidelidad (Paradoja Stock-Satisfacci√≥n)
    # ==========================================================================
    st.markdown("### üé≠ Pregunta 4: Diagn√≥stico de Fidelidad")
    st.markdown("""
    > *¬øExisten categor√≠as con alta disponibilidad (stock alto) pero sentimiento negativo?
    > ¬øEs mala calidad de producto o sobrecosto?*
    """)
    
    paradox_charts = create_fidelity_paradox_charts(df_filtered, data['df_inventario'])
    customer_charts = create_customer_charts(df_filtered)
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(paradox_charts['paradoja_stock_nps'], use_container_width=True)
    with col2:
        if 'nps_categoria' in customer_charts:
            st.plotly_chart(customer_charts['nps_categoria'], use_container_width=True)
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(paradox_charts['matriz_rendimiento'], use_container_width=True)
    with col2:
        if 'tickets_categoria' in customer_charts:
            st.plotly_chart(customer_charts['tickets_categoria'], use_container_width=True)
    
    # An√°lisis de la paradoja
    st.markdown("#### üîç An√°lisis de la Paradoja Stock-Satisfacci√≥n")
    
    # Calcular m√©tricas por categor√≠a
    df_fb = df_filtered[df_filtered['Rating_Producto'].notna()].copy()
    stock_cat = data['df_inventario'].groupby('Categoria')['Stock_Actual'].sum().reset_index()
    stock_cat.columns = ['Categoria', 'Stock_Total']
    
    sentiment_cat = df_fb.groupby('Categoria').agg({
        'Satisfaccion_NPS': 'mean',
        'Rating_Producto': 'mean',
        'Precio_Venta_Final': 'mean',
        'Costo_Unitario_USD': 'mean'
    }).reset_index()
    sentiment_cat.columns = ['Categoria', 'NPS', 'Rating', 'Precio_Prom', 'Costo_Prom']
    
    paradox_analysis = stock_cat.merge(sentiment_cat, on='Categoria', how='inner')
    paradox_analysis = paradox_analysis[paradox_analysis['Categoria'].notna()]
    paradox_analysis['Margen_Prom'] = paradox_analysis['Precio_Prom'] - paradox_analysis['Costo_Prom']
    paradox_analysis['Stock_Normalizado'] = paradox_analysis['Stock_Total'] / paradox_analysis['Stock_Total'].max() * 100
    
    # Identificar categor√≠as con paradoja
    alto_stock = paradox_analysis['Stock_Normalizado'] > 50
    bajo_nps = paradox_analysis['NPS'] < paradox_analysis['NPS'].median()
    paradox_analysis['Paradoja'] = alto_stock & bajo_nps
    
    categorias_paradoja = paradox_analysis[paradox_analysis['Paradoja'] == True]
    
    if len(categorias_paradoja) > 0:
        st.warning(f"‚ö†Ô∏è Se detectaron {len(categorias_paradoja)} categor√≠as con la paradoja Alto Stock + Bajo NPS")
        st.dataframe(
            categorias_paradoja[['Categoria', 'Stock_Total', 'NPS', 'Rating', 'Precio_Prom', 'Costo_Prom', 'Margen_Prom']].style.format({
                'Stock_Total': '{:,.0f}',
                'NPS': '{:.1f}',
                'Rating': '{:.2f}',
                'Precio_Prom': '${:,.2f}',
                'Costo_Prom': '${:,.2f}',
                'Margen_Prom': '${:,.2f}'
            }),
            use_container_width=True
        )
    else:
        st.success("‚úÖ No se detectaron categor√≠as con la paradoja Alto Stock + Bajo NPS")
    
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(customer_charts['rating_scatter'], use_container_width=True)
    with col2:
        if 'recomendacion' in customer_charts:
            st.plotly_chart(customer_charts['recomendacion'], use_container_width=True)
    
    st.markdown("---")
    
    # ==========================================================================
    # PREGUNTA 5: Storytelling de Riesgo Operativo
    # ==========================================================================
    st.markdown("### üèöÔ∏è Pregunta 5: Storytelling de Riesgo Operativo")
    st.markdown("""
    > *¬øQu√© relaci√≥n existe entre la antig√ºedad de la √∫ltima revisi√≥n de stock y la tasa de tickets de soporte?
    > ¬øQu√© bodegas operan a ciegas?*
    """)
    
    revision_charts = create_stock_revision_charts(df_filtered, data['df_inventario'])
    
    col1, col2 = st.columns(2)
    with col1:
        if 'dias_revision_bodega' in revision_charts:
            st.plotly_chart(revision_charts['dias_revision_bodega'], use_container_width=True)
    with col2:
        if 'tickets_vs_revision' in revision_charts:
            st.plotly_chart(revision_charts['tickets_vs_revision'], use_container_width=True)
    
    if 'bodegas_ciegas' in revision_charts:
        st.plotly_chart(revision_charts['bodegas_ciegas'], use_container_width=True)
    
    # An√°lisis de bodegas operando a ciegas
    st.markdown("#### üî¶ Bodegas Operando a Ciegas (Sin Revisi√≥n >180 d√≠as)")
    
    df_inv = data['df_inventario']
    bodegas_ciegas = df_inv[df_inv['Dias_Sin_Revision'] > 180].groupby('Bodega_Origen').agg({
        'SKU_ID': 'count',
        'Stock_Actual': 'sum',
        'Dias_Sin_Revision': ['mean', 'max']
    }).reset_index()
    bodegas_ciegas.columns = ['Bodega', 'SKUs Desactualizados', 'Stock en Riesgo', 'D√≠as Promedio', 'D√≠as M√°ximo']
    
    if len(bodegas_ciegas) > 0:
        st.error(f"üö® {len(bodegas_ciegas)} bodegas tienen productos sin revisi√≥n por m√°s de 180 d√≠as")
        st.dataframe(
            bodegas_ciegas.style.format({
                'Stock en Riesgo': '{:,.0f}',
                'D√≠as Promedio': '{:.0f}',
                'D√≠as M√°ximo': '{:.0f}'
            }),
            use_container_width=True
        )
        
        # Impacto en tickets
        df_merge_revision = df_filtered[df_filtered['Dias_Sin_Revision'].notna() & df_filtered['Ticket_Soporte_Abierto'].notna()].copy()
        if len(df_merge_revision) > 0:
            corr_revision_tickets = df_merge_revision['Dias_Sin_Revision'].corr(
                df_merge_revision['Ticket_Soporte_Abierto'].astype(float)
            )
            st.info(f"üìà Correlaci√≥n entre d√≠as sin revisi√≥n y tickets de soporte: **{corr_revision_tickets:.3f}**")
    else:
        st.success("‚úÖ Todas las bodegas tienen revisiones recientes (<180 d√≠as)")


def render_insights_tab(df_filtered, data):
    """
    Renderiza la pesta√±a de Insights de IA.
    """
    st.markdown("## ü§ñ Insights Generados por IA")
    st.markdown("""
    Esta secci√≥n utiliza el modelo **Llama-3** de Groq para generar recomendaciones estrat√©gicas
    basadas en los datos filtrados actualmente.
    """)
    
    # Input de API Key
    st.markdown("### üîë Configuraci√≥n de API")
    
    # Intentar obtener API key de secrets o variable de entorno
    api_key = st.text_input(
        "API Key de Groq",
        type="password",
        help="Ingrese su API Key de Groq. Obt√©ngala en https://console.groq.com/",
        value=os.environ.get('GROQ_API_KEY', '')
    )
    
    if not api_key:
        st.warning("‚ö†Ô∏è Ingrese su API Key de Groq para generar insights con IA")
        st.info("""
        **¬øNo tienes una API Key?**
        1. Ve a [console.groq.com](https://console.groq.com/)
        2. Crea una cuenta gratuita
        3. Genera una API Key en la secci√≥n 'API Keys'
        """)
        return
    
    # Mostrar resumen de datos actuales
    st.markdown("### üìä Datos Actualmente Filtrados")
    
    kpis = calculate_kpis(df_filtered)
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Transacciones", f"{len(df_filtered):,}")
    with col2:
        st.metric("Ingresos", format_currency(kpis['ingresos_totales']))
    with col3:
        st.metric("Margen", format_percentage(kpis['margen_porcentaje_global']))
    
    st.markdown("---")
    
    # Bot√≥n para generar insights
    if st.button("üöÄ Generar Recomendaciones Estrat√©gicas", use_container_width=True, type="primary"):
        with st.spinner("Analizando datos y generando recomendaciones..."):
            try:
                insights = generate_ai_insights(df_filtered, kpis, api_key)
                
                st.markdown("### üí° Recomendaciones Estrat√©gicas")
                st.markdown("---")
                st.markdown(insights)
                st.markdown("---")
                
                # Opci√≥n de descarga
                st.download_button(
                    label="üì• Descargar Recomendaciones",
                    data=f"RECOMENDACIONES ESTRAT√âGICAS - TechLogistics S.A.\n\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n{insights}",
                    file_name=f"recomendaciones_ia_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain"
                )
                
            except Exception as e:
                st.error(f"Error al generar insights: {str(e)}")
                st.info("Verifique que su API Key sea v√°lida y tenga cr√©ditos disponibles.")


# =============================================================================
# APLICACI√ìN PRINCIPAL
# =============================================================================

def main():
    """
    Funci√≥n principal de la aplicaci√≥n.
    """
    # Header
    st.markdown('<p class="main-header">üè¢ TechLogistics S.A.</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Dashboard | Sistema de Soporte a la Decisi√≥n (DSS)</p>', unsafe_allow_html=True)
    
    # Cargar datos
    try:
        # Rutas de los archivos
        data_path = "datasets"
        inv_path = os.path.join(data_path, "inventario_central_v2.csv")
        trans_path = os.path.join(data_path, "transacciones_logistica_v2.csv")
        feed_path = os.path.join(data_path, "feedback_clientes_v2.csv")
        
        # Verificar existencia de archivos
        if not all(os.path.exists(p) for p in [inv_path, trans_path, feed_path]):
            st.error("‚ö†Ô∏è No se encontraron los archivos de datos. Aseg√∫rese de que los archivos CSV est√©n en la carpeta 'datasets/'")
            st.info("""
            Archivos requeridos:
            - datasets/inventario_central_v2.csv
            - datasets/transacciones_logistica_v2.csv
            - datasets/feedback_clientes_v2.csv
            """)
            return
        
        # Cargar y procesar datos
        with st.spinner("Cargando y procesando datos..."):
            data = load_and_process_data(inv_path, trans_path, feed_path)
        
        # Renderizar sidebar y obtener filtros
        filters = render_sidebar(data)
        
        # Aplicar filtros
        df_filtered = apply_filters(data['df_merged'], filters)
        
        # Mostrar contador de registros filtrados
        st.markdown(f"**üìã Registros mostrados:** {len(df_filtered):,} de {len(data['df_merged']):,}")
        
        # Tabs principales
        tab1, tab2, tab3, tab4 = st.tabs([
            "üî¨ Auditor√≠a de Datos",
            "üè≠ Operaciones",
            "üë• Cliente",
            "ü§ñ Insights IA"
        ])
        
        with tab1:
            render_auditoria_tab(data)
        
        with tab2:
            render_operaciones_tab(df_filtered, data)
        
        with tab3:
            render_cliente_tab(df_filtered, data)
        
        with tab4:
            render_insights_tab(df_filtered, data)
        
        # Footer
        st.markdown("---")
        st.markdown("""
        <div style='text-align: center; color: #666; font-size: 0.8rem;'>
        TechLogistics S.A. DSS | Desarrollado por Gia Mariana Calle Higuita - Jos√© Santiago Molano Perdomo - Juan Jos√© Restrepo Higuita | SI6001 - Fundamentos en Ciencias de Datos | 2026
        </div>
        """, unsafe_allow_html=True)
        
    except Exception as e:
        st.error(f"Error al cargar la aplicaci√≥n: {str(e)}")
        st.exception(e)


if __name__ == "__main__":
    main()
